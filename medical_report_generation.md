
### Surveys & Thesis 

* Agrawal, Tejas Prakash. "**RadGraph: Integrating Fine-Grained and Global Features using GCNs and LLMs.**" PhD diss., Faculty of the Graduate School of the University at Buffalo, The State University of New York, 2024.
  [[PDF](https://cse.buffalo.edu/tech-reports/2024-19.pdf)] 

* **Vision-Language Models for Medical Report Generation and Visual Question Answering: A Review**, Iryna Hartsock, Ghulam Rasool
  [[Paper](https://arxiv.org/abs/2403.02469)] 

* Sloan, Phillip, et al. "**Automated Radiology Report Generation: A Review of Recent Advances.**" IEEE Reviews in Biomedical Engineering (2024).
  [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10545538)] 



### Big Project 

* [https://sites.research.google/med-palm/](https://sites.research.google/med-palm/)  





### Year 2024 


* [ECCV 2024] MedRAT: Unpaired Medical Report Generation via Auxiliary Tasks,
  [[Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08947.pdf)]
  [[Code](https://github.com/eladhi/MedRAT)]
  
* **InVERGe: Intelligent Visual Encoder for Bridging Modalities in Report Generation**,
  Ankan Deria, Komal Kumar, Snehashis Chakraborty, Dwarikanath Mahapatra, Sudipta Roy; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2024, pp. 2028-2038
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Deria_InVERGe_Intelligent_Visual_Encoder_for_Bridging_Modalities_in_Report_Generation_CVPRW_2024_paper.html)]

* **Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation**,
  Liwen Sun, James Zhao, Megan Han, Chenyan Xiong
  [[Paper](https://arxiv.org/abs/2407.15268)] 

* Jeong, Jaehwan, et al. "**Multimodal image-text matching improves retrieval-based chest x-ray report generation.**"
  Medical Imaging with Deep Learning. PMLR, 2024.
  [[Paper](https://proceedings.mlr.press/v227/jeong24a/jeong24a.pdf)]
  
* [arXiv:2409.13321] **SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**,
  Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu
  [[Paper](https://arxiv.org/abs/2409.13321)] 

* [arXiv:2408.15915] **Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models**,
  Yuncheng Yang, Yulei Qin, Tong Wu, Zihan Xu, Gang Li, Pengcheng Guo, Hang Shao, Yuchen Shi, Ke Li, Xing Sun, Jie Yang, Yun Gu
  [[Paper](https://arxiv.org/abs/2408.15915)] 

* [arXiv:2409.05370v1] **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**,
Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, and Luping Zhou
 [[Paper](https://arxiv.org/pdf/2409.05370)] 

* [arXiv:2405.04175] **Topicwise Separable Sentence Retrieval for Medical Report Generation**,
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/pdf/2405.04175)] 

* Fan, Yijian, Zhenbang Yang, Rui Liu, Mingjie Li, and Xiaojun Chang. "**Medical Report Generation Is A Multi-label Classification Problem.**" arXiv preprint arXiv:2409.00250 (2024).
  [[Paper](https://arxiv.org/pdf/2409.00250)] 


* [arXiv:2403.05396] **HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction**,
  Zhengrui Guo, Jiabo Ma, Yingxue Xu, Yihui Wang, Liansheng Wang, and Hao Chen
  [[Paper](https://arxiv.org/abs/2403.05396)] 
  
* [arXiv:2408.14397] **Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs**,
  Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar
  [[Paper](https://arxiv.org/abs/2408.14397)]
  [[Code](https://github.com/rajpurkarlab/ReXKG)]
  
* [arXiv:2408.12141] **TRRG: Towards Truthful Radiology Report Generation With Cross-modal Disease Clue Enhanced Large Language Model**,
  Yuhao Wang, Chao Hao, Yawen Cui, Xinqi Su, Weicheng Xie, Tao Tan, Zitong Yu
  [[Paper](https://arxiv.org/abs/2408.12141)]
  
* [arXiv:2405.14113] **Multi-modality Regional Alignment Network for Covid X-Ray Survival Prediction and Report Generation**, Zhusi Zhong, Jie Li, John Sollee, Scott Collins, Harrison Bai, Paul Zhang, Terrence Healey, Michael Atalay, Xinbo Gao, Zhicheng Jiao 
  [[Paper](https://arxiv.org/abs/2405.14113)]
  [[Code](https://github.com/zzs95/MRANet)] 

* [arXiv:2408.03500] **e-Health CSIRO at RRG24: Entropy-Augmented Self-Critical Sequence Training for Radiology Report Generation**,
  Aaron Nicolson, Jinghui Liu, Jason Dowling, Anthony Nguyen, Bevan Koopman
  [[Paper](https://arxiv.org/abs/2408.03500)]
  [[Code](https://huggingface.co/aehrc/cxrmate-rrg24)] 
  
* [ACM MM 2024] **In-Context Learning for Zero-shot Medical Report Generation**,
  RUI Liu, Mingjie Li, Shen Zhao, Ling Chen, Xiaojun Chang, Lina Yao
  [[Paper](https://openreview.net/pdf?id=8zyG2eUgVE)] 

* [Nature 2023] Singhal, K., Azizi, S., Tu, T. et al. **Large language models encode clinical knowledge.** Nature 620, 172–180 (2023). https://doi.org/10.1038/s41586-023-06291-2
  [[Paper](https://www.nature.com/articles/s41586-023-06291-2)] 

* [Med-PaLM 2] **Towards Expert-Level Medical Question Answering with Large Language Models**,
  [[Paper](https://arxiv.org/pdf/2305.09617)]
  
* [Med-PaLM Multimodal (Med-PaLM M)] **Towards Generalist Biomedical AI**,
  Tao Tu∗, ‡, 1, Shekoofeh Azizi
  [[Paper](https://arxiv.org/pdf/2307.14334)]   
  
* [MedVersa] **A Generalist Learner for Multifaceted Medical Image Interpretation**, 
  Hong-Yu Zhou, Subathra Adithan, Julián Nicolás Acosta, Eric J. Topol, Pranav Rajpurkar
  [[Paper](https://arxiv.org/abs/2405.07988)] 
  
* [arXiv:2403.08002v2] **Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging**, 
Juan Manuel Zambrano Chaves, Shih-Cheng Huang, Yanbo Xu, Hanwen Xu, Naoto Usuyama, Sheng Zhang, Fei Wang, Yujia Xie, Mahmoud Khademi, Ziyi Yang, Hany Awadalla, Julia Gong, Houdong Hu, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Yu Gu, Cliff Wong, Mu Wei, Tristan Naumann, Muhao Chen, Matthew P. Lungren, Serena Yeung-Levy, Curtis P. Langlotz, Sheng Wang, Hoifung Poon
[[Paper](https://arxiv.org/abs/2403.08002v2)]   

* [arXiv:2403.08002] **Towards a clinically accessible radiology foundation model: open-access and lightweight, with automated evaluation**, 
  Juan Manuel Zambrano Chaves, Shih-Cheng Huang, Yanbo Xu, Hanwen Xu, Naoto Usuyama, Sheng Zhang, Fei Wang, Yujia Xie, Mahmoud Khademi, Ziyi Yang, Hany Awadalla, Julia Gong, Houdong Hu, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Yu Gu, Cliff Wong, Mu Wei, Tristan Naumann, Muhao Chen, Matthew P. Lungren, Akshay Chaudhari, Serena Yeung-Levy, Curtis P. Langlotz, Sheng Wang, Hoifung Poon
  [[Paper](https://arxiv.org/abs/2403.08002)]
  [[CheXprompt (Code)](https://github.com/microsoft/chexprompt)] 

* [CVPR2024] **MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant**,
  Chenlu Zhan, Yu Lin, Gaoang Wang, Hongwei Wang, Jian Wu
  [[Paper](https://arxiv.org/abs/2403.04290)] 

* **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**,
  Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas
  [[Paper](https://arxiv.org/abs/2407.21638)] 

* Zhao B N, JIANG X, Luo X, et al. **Large Multimodal Model for Real-World Radiology Report Generation**[J].
  [[Paper](https://openreview.net/pdf?id=3Jl0sjmZx9)]

* **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**, Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen
  [[Paper](https://arxiv.org/abs/2407.15362)]
  
* [arXiv:2407.15158] **HERGen: Elevating Radiology Report Generation with Longitudinal Data**, Fuying Wang, Shenghui Du, Lequan Yu, ECCV 2024, 
  [[Paper](https://arxiv.org/abs/2407.15158)]
  [[Code](https://github.com/fuying-wang/HERGen)] 
  
* **Eye Gaze Guided Cross-Modal Alignment Network for Radiology Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10596697)]  

* [ECCV 2024] **Contrastive Learning with Counterfactual Explanations for Radiology Report Generation**, 
  [[Paper](https://arxiv.org/pdf/2407.14474)]
  [[Code](https://github.com/mlii0117/CoFE)] 

* [IEEE TMI 2024] **Multi-Grained Radiology Report Generation With Sentence-Level Image-Language Contrastive Learning**, 
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10458706)] 

* [IEEE TMI 2024] **PhraseAug: An Augmented Medical Report Generation Model with Phrasebook**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10560051)] 

* [IEEE TMM 2023] **Semi-Supervised Medical Report Generation via Graph-Guided Hybrid Feature Consistency**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)] 

* [IEEE TMI 2024] **SGT++: Improved Scene Graph-Guided Transformer for Surgical Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10330637)] 

* [IEEE TNNLS] **Hybrid Reinforced Medical Report Generation With M-Linear Attention and Repetition Penalty**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10373187)]  

* [CIKM '23] Li, Qi. "**Harnessing the power of pre-trained vision-language models for efficient medical report generation**." Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 2023.

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMI 2024] **ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10522762)]
  [[Code](https://github.com/zhaozh10/ChatCAD)] 

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMM 2023] Multi-Task Paired Masking With Alignment Modeling for Medical Vision-Language Pre-Training
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10288259)]

* [IEEE TMI 2024] **Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting**
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10552817)]
  [[Code](https://github.com/yangyan22/Token-Mixer)] 
  
* [arXiv:2405.04175] **Topic-wise Separable Sentence Retrieval for Medical Report Generation**,
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/abs/2405.04175)] 

* [WACV 2024] **CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs**,
  Junjie Shentu, Noura Al Moubayed,
  [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Shentu_CXR-IRGen_An_Integrated_Vision_and_Language_Model_for_the_Generation_WACV_2024_paper.pdf)]
  [[Code](https://github.com/junjie-shentu/CXR-IRGen)]

* [CVPR-2024] **Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation**, Shenshen Bu, Taiji Li, Yuedong Yang,*Zhiming Dai 
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.pdf)]
  [[Code](https://github.com/hnjzbss/EKAGen)] 

* [arXiv:2406.04449] **MAIRA-2: Grounded Radiology Report Generation**, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Anton Schwaighofer, Sam Bond-Taylor, Maximilian Ilse, Fernando Pérez-García, Valentina Salvatelli, Harshita Sharma, Felix Meissen, Mercy Ranjit, Shaury Srivastav, Julia Gong, Fabian Falck, Ozan Oktay, Anja Thieme, Matthew P. Lungren, Maria Teodora Wetscherek, Javier Alvarez-Valle, Stephanie L. Hyland
  [[Paper](https://arxiv.org/abs/2406.04449)] 

* [MICCAI 2024] **Textual Inversion and Self-supervised Refinement for Radiology Report Generation**, Yuanjiang Luo, Hongxiang Li, Xuan Wu, Meng Cao, Xiaoshuang Huang, Zhihong Zhu, Peixi Liao, Hu Chen, Yi Zhang
  [[Paper](https://arxiv.org/abs/2405.20607)]

* [arXiv:2405.19654] **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**,
  Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen
  [[Paper](https://arxiv.org/abs/2405.19654)]
  [[Code](https://github.com/SVT-Yang/MedST)] 

* [arXiv:2405.14113] **Multi-modality Regional Alignment Network for Covid X-Ray Survival Prediction and Report Generation**, 
  Zhusi Zhong, Jie Li, John Sollee, Scott Collins, Harrison Bai, Paul Zhang, Terrence Healey, Michael Atalay, Xinbo Gao, Zhicheng Jiao
  [[Paper](https://arxiv.org/abs/2405.14113)] 


* **FITA: Fine-grained Image-Text Aligner for Radiology Report Generation**,
  Honglong Yang, Hui Tang, Xiaomeng Li
  [[Paper](https://arxiv.org/abs/2405.00962)] 

* **A Disease Labeler for Chinese Chest X-Ray Report Generation**, arXiv:2404.16852, 
  Mengwei Wang, Ruixin Yan, Zeyi Hou, Ning Lang, Xiuzhuang Zhou
  [[Paper](https://arxiv.org/abs/2404.16852)] 

* "**Bootstrapping Large Language Models for Radiology Report Generation.**" Liu, Chang, et al.
Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 17. 2024.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/29826)]
[[Code](https://github.com/synlp/R2-LLM)]

* [ICME 2024] **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**, arXiv:2404.11209, 
  Hongzhao Li, Hongyu Wang, Xia Sun, Hua He, Jun Feng
  [[Paper](https://arxiv.org/abs/2404.11209)] 

* [CVPR2024] **MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant**, Chenlu Zhan, Yu Lin, Gaoang Wang, Hongwei Wang, Jian Wu
  [[Paper](https://arxiv.org/abs/2403.04290)] 
 
* [AAAI-2024] **PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation**, Haibo Jin1 , Haoxuan Che1, Yi Lin1, and Hao Chen
  [[Paper](https://arxiv.org/pdf/2308.12604.pdf)]
  [[Code](https://github.com/jhb86253817/PromptMRG)]

* [AAAI-2024] **MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models**, Yan Cai; Linlin Wang; Ye Wang; Gerard de Melo; Ya Zhang; Yan-Feng Wang; Liang He
  [[Paper](https://arxiv.org/abs/2312.12806)]







### Year 2023 


* Li M, Lin B, Chen Z, et al. **Dynamic graph enhanced contrastive learning for chest x-ray report generation**[C]//
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3334-3343.
  [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Dynamic_Graph_Enhanced_Contrastive_Learning_for_Chest_X-Ray_Report_Generation_CVPR_2023_paper.pdf)]
  [[Code](https://github.com/mlii0117/DCL)] 
  
* Yang, Shuxin, et al. "**Radiology report generation with a learned knowledge base and multi-modal alignment.**" Medical Image Analysis 86 (2023): 102798.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841523000592)]
  [[Code](https://github.com/LX-doctorAI1/M2KT)]

* [MICCAI workshop 2023] Xiong, Yiheng, et al. "**Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for Generating Radiology Graphs from X-Rays.**"
  International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature, Switzerland, 2023.
  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-55088-1_5)]
  [[Code](https://github.com/xiongyiheng/Prior-RadGraphFormer)] 

* [arXiv:2312.03970] **Improving Medical Report Generation with Adapter Tuning and Knowledge Enhancement in Vision-Language Foundation Models**, Shibin Wu, Bang Yang, Zhiyu Ye, Haoqian Wang, Hairong Zheng, Tong Zhang
  [[Paper](https://arxiv.org/abs/2312.03970)] 
  
* [arXiv:2303.09117] **Cross-Modal Causal Intervention for Medical Report Generation**, Weixing Chen, Yang Liu, Ce Wang, Jiarui Zhu, Shen Zhao, Guanbin Li, Cheng-Lin Liu, Liang Lin
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)] 

* [arXiv:2307.12526] **Rethinking Medical Report Generation: Disease Revealing Enhancement with Knowledge Graph**, Yixin Wang, Zihao Lin, Haoyu Dong
  [[Paper](https://arxiv.org/abs/2307.12526)] 

* [arXiv:2307.09758] **Longitudinal Data and a Semantic Similarity Reward for Chest X-Ray Report Generation**, Aaron Nicolson, Jason Dowling, Bevan Koopman
  [[Paper](https://arxiv.org/abs/2307.09758)]
  [[Code](https://github.com/aehrc/cxrmate)]

* "**Improving chest X-ray report generation by leveraging warm starting.**" Nicolson, Aaron, Jason Dowling, and Bevan Koopman.  Artificial intelligence in medicine 144 (2023): 102633.
[[Paper](https://www.sciencedirect.com/science/article/pii/S0933365723001471)]
[[Code](https://github.com/aehrc/cvt2distilgpt2)] 

* [arXiv:2310.05881, EMNLP 2023] **Controllable Chest X-Ray Report Generation from Longitudinal Representations**,
  Francesco Dalla Serra, Chaoyang Wang, Fani Deligianni, Jeffrey Dalton, Alison Q O'Neil
  [[Paper](https://arxiv.org/abs/2310.05881)] 

* **RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance**, Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher
  [[Paper](https://arxiv.org/abs/2311.18681)]
  [[Code](https://github.com/ChantalMP/RaDialog)] 

* **Visual-linguistic causal intervention for radiology report generation.** Chen, W., Liu, Y., Wang, C., Li, G., Zhu, J., & Lin, L. (2023). arXiv preprint arXiv:2303.09117.
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)]

* Zhang, Ke, et al. "**Semi-supervised Medical Report Generation via Graph-guided Hybrid Feature Consistency.**" IEEE Transactions on Multimedia (2023).
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)]

* [ACL-2023] **ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning**, Wenjun Hou, Kaishuai Xu, Yi Cheng, Wenjie Li, Jiang Liu
  [[Paper](https://arxiv.org/pdf/2306.06466.pdf)]
  [[Code](https://github.com/wjhou/ORGan)]

* [EMNLP-2023] Hou, Wenjun, et al. "**RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning.**" Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.
  [[Paper](https://aclanthology.org/2023.findings-emnlp.140.pdf)]
  [[Code](https://github.com/wjhou/Recap)]





### Year 2022 


* **Uncertainty-aware report generation for chest X-rays by variational topic inference**,
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522002341?ref=pdf_download&fr=RR-2&rr=8c83a1612fa3dda2)] 

* **Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors**, Machine Learning for Health (ML4H) 2022
  [[Paper](https://proceedings.mlr.press/v193/ramesh22a/ramesh22a.pdf)] 

* Yang, Shuxin, et al. "**Knowledge matters: Chest radiology report generation with general and specific knowledge.**" Medical image analysis 80 (2022): 102510.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522001578)]
  [[Code](https://github.com/LX-doctorAI1/GSKET)] 

* [ECCV-2022] **Cross-modal prototype driven network for radiology report generation**. In European Conference on Computer Vision (pp. 563-579). Wang, J., Bhalerao, A., & He, Y. (2022, October). Cham: Springer Nature Switzerland.
  [[Paper](https://arxiv.org/pdf/2207.04818.pdf)]
  [[Code](https://github.com/Markin-Wang/XProNet)]

* Najdenkoska I, Zhen X, Worring M, et al. **Uncertainty-aware report generation for chest X-rays by variational topic inference**[J]. Medical Image Analysis, 2022, 82: 102603.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522002341)]


### Year 2021 and Before 


* Endo M, Krishnan R, Krishna V, et al. **Retrieval-based chest x-ray report generation using a pre-trained contrastive language-image model**[C]//Machine Learning for Health. PMLR, 2021: 209-219.
  [[Paper](https://proceedings.mlr.press/v158/endo21a/endo21a.pdf)] 
  [[Code](https://github.com/rajpurkarlab/CXR-RePaiR)] 

* "**Cross-modal Memory Networks for Radiology Report Generation.**" Chen, Zhihong, et al.  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.
  [[Paper](https://aclanthology.org/2021.acl-long.459/)]
  [[R2GenCMN-Code](https://github.com/zhjohnchan/R2GenCMN)]

* **On the Automatic Generation of Medical Imaging Reports**, Baoyu Jing, Pengtao Xie, Eric Xing
  [[Paper](https://arxiv.org/abs/1711.08195)]
  [[Code](https://github.com/ZexinYan/Medical-Report-Generation)] 

* [AAAI 2019] **CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison**,
  Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong, Safwan S. Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel, Matthew P. Lungren, Andrew Y. Ng 
  [[Paper](https://arxiv.org/abs/1901.07031)]
  [[Code](https://stanfordmlgroup.github.io/competitions/chexpert)]
  [[chexpert-labeler](https://github.com/stanfordmlgroup/chexpert-labeler)]






