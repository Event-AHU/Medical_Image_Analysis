
### Surveys 

* **Vision-Language Models for Medical Report Generation and Visual Question Answering: A Review**, Iryna Hartsock, Ghulam Rasool
  [[Paper](https://arxiv.org/abs/2403.02469)] 



### Year 2024 

* Zhao B N, JIANG X, Luo X, et al. **Large Multimodal Model for Real-World Radiology Report Generation**[J].
  [[Paper](https://openreview.net/pdf?id=3Jl0sjmZx9)]

* **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**, Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen
  [[Paper](https://arxiv.org/abs/2407.15362)]
  
* [arXiv:2407.15158] **HERGen: Elevating Radiology Report Generation with Longitudinal Data**, Fuying Wang, Shenghui Du, Lequan Yu, ECCV 2024, 
  [[Paper](https://arxiv.org/abs/2407.15158)]
  [[Code](https://github.com/fuying-wang/HERGen)] 
  
* **Eye Gaze Guided Cross-Modal Alignment Network for Radiology Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10596697)]  

* [ECCV 2024] **Contrastive Learning with Counterfactual Explanations for Radiology Report Generation**, 
  [[Paper](https://arxiv.org/pdf/2407.14474)]
  [[Code](https://github.com/mlii0117/CoFE)] 

* [IEEE TMI 2024] **Multi-Grained Radiology Report Generation With Sentence-Level Image-Language Contrastive Learning**, 
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10458706)] 

* [IEEE TMI 2024] **PhraseAug: An Augmented Medical Report Generation Model with Phrasebook**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10560051)] 

* [IEEE TMM 2023] **Semi-Supervised Medical Report Generation via Graph-Guided Hybrid Feature Consistency**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)] 

* [IEEE TMI 2024] **SGT++: Improved Scene Graph-Guided Transformer for Surgical Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10330637)] 

* [IEEE TNNLS] **Hybrid Reinforced Medical Report Generation With M-Linear Attention and Repetition Penalty**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10373187)]  

* [CIKM '23] Li, Qi. "**Harnessing the power of pre-trained vision-language models for efficient medical report generation**." Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 2023.

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMI 2024] **ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10522762)]
  [[Code](https://github.com/zhaozh10/ChatCAD)] 

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMM 2023] Multi-Task Paired Masking With Alignment Modeling for Medical Vision-Language Pre-Training
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10288259)]

* [IEEE TMI 2024] **Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting**
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10552817)]
  [[Code](https://github.com/yangyan22/Token-Mixer)] 
  
* [arXiv:2405.04175] **Topic-wise Separable Sentence Retrieval for Medical Report Generation**,
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/abs/2405.04175)] 

* [WACV 2024] **CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs**,
  Junjie Shentu, Noura Al Moubayed,
  [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Shentu_CXR-IRGen_An_Integrated_Vision_and_Language_Model_for_the_Generation_WACV_2024_paper.pdf)]
  [[Code](https://github.com/junjie-shentu/CXR-IRGen)]

* [CVPR-2024] **Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation**, Shenshen Bu, Taiji Li, Yuedong Yang,*Zhiming Dai 
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.pdf)]
  [[Code](https://github.com/hnjzbss/EKAGen)] 

* [arXiv:2406.04449] **MAIRA-2: Grounded Radiology Report Generation**, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Anton Schwaighofer, Sam Bond-Taylor, Maximilian Ilse, Fernando Pérez-García, Valentina Salvatelli, Harshita Sharma, Felix Meissen, Mercy Ranjit, Shaury Srivastav, Julia Gong, Fabian Falck, Ozan Oktay, Anja Thieme, Matthew P. Lungren, Maria Teodora Wetscherek, Javier Alvarez-Valle, Stephanie L. Hyland
  [[Paper](https://arxiv.org/abs/2406.04449)] 

* [arXiv:2405.20607] **Textual Inversion and Self-supervised Refinement for Radiology Report Generation**, Yuanjiang Luo, Hongxiang Li, Xuan Wu, Meng Cao, Xiaoshuang Huang, Zhihong Zhu, Peixi Liao, Hu Chen, Yi Zhang
  [[Paper](https://arxiv.org/abs/2405.20607)]

* [arXiv:2405.19654] **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**,
  Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen
  [[Paper](https://arxiv.org/abs/2405.19654)]
  [[Code](https://github.com/SVT-Yang/MedST)] 

* [arXiv:2405.14113] **Multi-modality Regional Alignment Network for Covid X-Ray Survival Prediction and Report Generation**, 
  Zhusi Zhong, Jie Li, John Sollee, Scott Collins, Harrison Bai, Paul Zhang, Terrence Healey, Michael Atalay, Xinbo Gao, Zhicheng Jiao
  [[Paper](https://arxiv.org/abs/2405.14113)] 

* **Topicwise Separable Sentence Retrieval for Medical Report Generation**, arXiv:2405.04175, 
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/abs/2405.04175)]
  
* **FITA: Fine-grained Image-Text Aligner for Radiology Report Generation**,
  Honglong Yang, Hui Tang, Xiaomeng Li
  [[Paper](https://arxiv.org/abs/2405.00962)] 

* **A Disease Labeler for Chinese Chest X-Ray Report Generation**, arXiv:2404.16852, 
  Mengwei Wang, Ruixin Yan, Zeyi Hou, Ning Lang, Xiuzhuang Zhou
  [[Paper](https://arxiv.org/abs/2404.16852)] 

* "**Bootstrapping Large Language Models for Radiology Report Generation.**" Liu, Chang, et al.
Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 17. 2024.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/29826)]
[[Code](https://github.com/synlp/R2-LLM)]

* **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**, arXiv:2404.11209, 
  Hongzhao Li, Hongyu Wang, Xia Sun, Hua He, Jun Feng
  [[Paper](https://arxiv.org/abs/2404.11209)] 

* [CVPR2024] **MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant**, Chenlu Zhan, Yu Lin, Gaoang Wang, Hongwei Wang, Jian Wu
  [[Paper](https://arxiv.org/abs/2403.04290)] 
 
* [AAAI-2024] **PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation**, Haibo Jin1 , Haoxuan Che1, Yi Lin1, and Hao Chen
  [[Paper](https://arxiv.org/pdf/2308.12604.pdf)]
  [[Code](https://github.com/jhb86253817/PromptMRG)]

* [AAAI-2024] **MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models**, Yan Cai; Linlin Wang; Ye Wang; Gerard de Melo; Ya Zhang; Yan-Feng Wang; Liang He
  [[Paper](https://arxiv.org/abs/2312.12806)]







### Year 2023 


* [arXiv:2303.09117] **Cross-Modal Causal Intervention for Medical Report Generation**, Weixing Chen, Yang Liu, Ce Wang, Jiarui Zhu, Shen Zhao, Guanbin Li, Cheng-Lin Liu, Liang Lin
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)] 

* [arXiv:2307.12526] **Rethinking Medical Report Generation: Disease Revealing Enhancement with Knowledge Graph**, Yixin Wang, Zihao Lin, Haoyu Dong
  [[Paper](https://arxiv.org/abs/2307.12526)] 

* [arXiv:2307.09758] **Longitudinal Data and a Semantic Similarity Reward for Chest X-Ray Report Generation**, Aaron Nicolson, Jason Dowling, Bevan Koopman
  [[Paper](https://arxiv.org/abs/2307.09758)]
  [[Code](https://github.com/aehrc/cxrmate)]

* "**Improving chest X-ray report generation by leveraging warm starting.**" Nicolson, Aaron, Jason Dowling, and Bevan Koopman.  Artificial intelligence in medicine 144 (2023): 102633.
[[Paper](https://www.sciencedirect.com/science/article/pii/S0933365723001471)]
[[Code](https://github.com/aehrc/cvt2distilgpt2)] 

* [arXiv:2310.05881, EMNLP 2023] **Controllable Chest X-Ray Report Generation from Longitudinal Representations**,
  Francesco Dalla Serra, Chaoyang Wang, Fani Deligianni, Jeffrey Dalton, Alison Q O'Neil
  [[Paper](https://arxiv.org/abs/2310.05881)] 

* **RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance**, Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher
  [[Paper](https://arxiv.org/abs/2311.18681)]
  [[Code](https://github.com/ChantalMP/RaDialog)] 

* **Visual-linguistic causal intervention for radiology report generation.** Chen, W., Liu, Y., Wang, C., Li, G., Zhu, J., & Lin, L. (2023). arXiv preprint arXiv:2303.09117.
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)]

* Zhang, Ke, et al. "**Semi-supervised Medical Report Generation via Graph-guided Hybrid Feature Consistency.**" IEEE Transactions on Multimedia (2023).
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)]

* [ACL-2023] **ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning**, Wenjun Hou, Kaishuai Xu, Yi Cheng, Wenjie Li, Jiang Liu
  [[Paper](https://arxiv.org/pdf/2306.06466.pdf)]
  [[Code](https://github.com/wjhou/ORGan)]

* [EMNLP-2023] Hou, Wenjun, et al. "**RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning.**" Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.
  [[Paper](https://aclanthology.org/2023.findings-emnlp.140.pdf)]
  [[Code](https://github.com/wjhou/Recap)]


### Year 2022 

* [ECCV-2022] **Cross-modal prototype driven network for radiology report generation**. In European Conference on Computer Vision (pp. 563-579). Wang, J., Bhalerao, A., & He, Y. (2022, October). Cham: Springer Nature Switzerland.
  [[Paper](https://arxiv.org/pdf/2207.04818.pdf)]
  [[Code](https://github.com/Markin-Wang/XProNet)]




### Year 2021 and Before 

* "**Cross-modal Memory Networks for Radiology Report Generation.**" Chen, Zhihong, et al.  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.
  [[Paper](https://aclanthology.org/2021.acl-long.459/)]
  [[R2GenCMN-Code](https://github.com/zhjohnchan/R2GenCMN)]

* **On the Automatic Generation of Medical Imaging Reports**, Baoyu Jing, Pengtao Xie, Eric Xing
  [[Paper](https://arxiv.org/abs/1711.08195)]
  [[Code](https://github.com/ZexinYan/Medical-Report-Generation)] 

* [AAAI 2019] **CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison**,
  Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong, Safwan S. Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel, Matthew P. Lungren, Andrew Y. Ng 
  [[Paper](https://arxiv.org/abs/1901.07031)]
  [[Code](https://stanfordmlgroup.github.io/competitions/chexpert)]
  [[chexpert-labeler](https://github.com/stanfordmlgroup/chexpert-labeler)]






