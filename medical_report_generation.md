
### Surveys & Thesis 

* Agrawal, Tejas Prakash. "**RadGraph: Integrating Fine-Grained and Global Features using GCNs and LLMs.**" PhD diss., Faculty of the Graduate School of the University at Buffalo, The State University of New York, 2024.
  [[PDF](https://cse.buffalo.edu/tech-reports/2024-19.pdf)] 

* **Vision-Language Models for Medical Report Generation and Visual Question Answering: A Review**, Iryna Hartsock, Ghulam Rasool
  [[Paper](https://arxiv.org/abs/2403.02469)] 

* Sloan, Phillip, et al. "**Automated Radiology Report Generation: A Review of Recent Advances.**" IEEE Reviews in Biomedical Engineering (2024).
  [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10545538)] 

* **A Survey of Large Language Models in Medicine: Progress, Application, and Challenge**,
  [[Paper](https://arxiv.org/pdf/2311.05112)] 


### Big Project 

* [https://sites.research.google/med-palm/](https://sites.research.google/med-palm/)  





### Year 2024 


* **VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge**, Vishwesh Nath, Wenqi Li, Dong Yang, Andriy Myronenko, Mingxin Zheng, Yao Lu, Zhijian Liu, Hongxu Yin, Yee Man Law, Yucheng Tang, Pengfei Guo, Can Zhao, Ziyue Xu, Yufan He, Greg Heinrich, Stephen Aylward, Marc Edgar, Michael Zephyr, Pavlo Molchanov, Baris Turkbey, Holger Roth, Daguang Xu 
  [[Paper](https://arxiv.org/pdf/2411.12915)] 


* [WACV 2025] **ORID: Organ-Regional Information Driven Framework for Radiology Report Generation**,
  Tiancheng Gu, Kaicheng Yang, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai
  [[Paper](https://arxiv.org/abs/2411.13025)] 

* [ACM MM 2024]**Divide and Conquer: Isolating Normal-Abnormal Attributes in Knowledge Graph-Enhanced Radiology Report Generation**, Xiao Liang, Yanlei Zhang, Di Wang, Haodi Zhong, Ronghan Li, Quan Wang
  [[Paper](https://dl.acm.org/doi/10.1145/3664647.3681201)]
  [[Code](https://github.com/ecoxial2007/DCG_Enhanced_distilGPT2)]

* **MCL: Multi-view Enhanced Contrastive Learning for Chest X-ray Report Generation**, Kang Liu, Zhuoqi Ma, Kun Xie, Zhicheng Jiao, Qiguang Miao
  [[Paper](https://arxiv.org/abs/2411.10224)]
  [[Code](https://github.com/mk-runner/MCL)]
  
* **Decoding Report Generators: A Cyclic Vision-Language Adapter for Counterfactual Explanations**, 
  [[Paper](https://arxiv.org/pdf/2411.05261)] 

* **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**, 
  [[Paper](https://arxiv.org/pdf/2411.05085)]
  [[Project](https://bimcv.cipf.es/bimcv-projects/padchest-gr/)] 

* [AAAI24] **Automatic Radiology Reports Generation via Memory Alignment Network**, 
  Hongyu Shen, Mingtao Pei, Juncai Liu, Zhaoxing Tian
   [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/28279)]
  
* **Designing a Robust Radiology Report Generation System**, Sonit Singh 
  [[Paper](https://arxiv.org/abs/2411.01153)] 

* [NeurIPS24] **BenchX: A Unified Benchmark Framework for Medical Vision-Language Pretraining on Chest X-Rays**, 
  Yang Zhou, Tan Li Hui Faith, Yanyu Xu, Sicong Leng, Xinxing Xu, Yong Liu, Rick Siow Mong Goh
   [[Paper](https://arxiv.org/abs/2410.21969)]
   [[Code](https://github.com/yangzhou12/BenchX)]
  
* [ISBI2025] **R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation**, 
  Yongheng Sun, Yueh Z. Lee, Genevieve A. Woodard, Hongtu Zhu, Chunfeng Lian, Mingxia Liu
  [[Paper](https://arxiv.org/abs/2410.18135)] 

* [MICCAI 2024] **Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation**, Kang Liu, Zhuoqi Ma,  Xiaolu Kang, Zhusi Zhong, and Qiguang Miao
  [[Paper](https://papers.miccai.org/miccai-2024/paper/1768_paper.pdf)]
  [[Code]( https://github.com/mk-runner/SEI)] 

* [ECCV 2024] **ChEX: Interactive Localization and Region Description in Chest X-rays**, Philip Müller, Georgios Kaissis, and Daniel Rueckert
  [[Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03114.pdf)]
  [[Code](https://github.com/philip-mueller/chex)] 

* [ECCV 2024] **MedRAT: Unpaired Medical Report Generation via Auxiliary Tasks**,
  [[Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08947.pdf)]
  [[Code](https://github.com/eladhi/MedRAT)]
  
* **InVERGe: Intelligent Visual Encoder for Bridging Modalities in Report Generation**,
  Ankan Deria, Komal Kumar, Snehashis Chakraborty, Dwarikanath Mahapatra, Sudipta Roy; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2024, pp. 2028-2038
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024W/MULA/html/Deria_InVERGe_Intelligent_Visual_Encoder_for_Bridging_Modalities_in_Report_Generation_CVPRW_2024_paper.html)]

* **Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation**,
  Liwen Sun, James Zhao, Megan Han, Chenyan Xiong
  [[Paper](https://arxiv.org/abs/2407.15268)] 

* Jeong, Jaehwan, et al. "**Multimodal image-text matching improves retrieval-based chest x-ray report generation.**"
  Medical Imaging with Deep Learning. PMLR, 2024.
  [[Paper](https://proceedings.mlr.press/v227/jeong24a/jeong24a.pdf)]
  
* [arXiv:2409.13321] **SLaVA-CXR: Small Language and Vision Assistant for Chest X-ray Report Automation**,
  Jinge Wu, Yunsoo Kim, Daqian Shi, David Cliffton, Fenglin Liu, Honghan Wu
  [[Paper](https://arxiv.org/abs/2409.13321)] 

* [arXiv:2408.15915] **Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models**,
  Yuncheng Yang, Yulei Qin, Tong Wu, Zihan Xu, Gang Li, Pengcheng Guo, Hang Shao, Yuchen Shi, Ke Li, Xing Sun, Jie Yang, Yun Gu
  [[Paper](https://arxiv.org/abs/2408.15915)] 

* [arXiv:2409.05370v1] **KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models**,
Yingshu Li, Zhanyu Wang, Yunyi Liu, Lei Wang, Lingqiao Liu, and Luping Zhou
 [[Paper](https://arxiv.org/pdf/2409.05370)] 

* [arXiv:2405.04175] **Topicwise Separable Sentence Retrieval for Medical Report Generation**,
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/pdf/2405.04175)] 

* Fan, Yijian, Zhenbang Yang, Rui Liu, Mingjie Li, and Xiaojun Chang. "**Medical Report Generation Is A Multi-label Classification Problem.**" arXiv preprint arXiv:2409.00250 (2024).
  [[Paper](https://arxiv.org/pdf/2409.00250)] 


* [arXiv:2403.05396] **HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction**,
  Zhengrui Guo, Jiabo Ma, Yingxue Xu, Yihui Wang, Liansheng Wang, and Hao Chen
  [[Paper](https://arxiv.org/abs/2403.05396)] 
  
* [arXiv:2408.14397] **Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs**,
  Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar
  [[Paper](https://arxiv.org/abs/2408.14397)]
  [[Code](https://github.com/rajpurkarlab/ReXKG)]
  
* [arXiv:2408.12141] **TRRG: Towards Truthful Radiology Report Generation With Cross-modal Disease Clue Enhanced Large Language Model**,
  Yuhao Wang, Chao Hao, Yawen Cui, Xinqi Su, Weicheng Xie, Tao Tan, Zitong Yu
  [[Paper](https://arxiv.org/abs/2408.12141)]
  
* [arXiv:2405.14113] **Multi-modality Regional Alignment Network for Covid X-Ray Survival Prediction and Report Generation**, Zhusi Zhong, Jie Li, John Sollee, Scott Collins, Harrison Bai, Paul Zhang, Terrence Healey, Michael Atalay, Xinbo Gao, Zhicheng Jiao 
  [[Paper](https://arxiv.org/abs/2405.14113)]
  [[Code](https://github.com/zzs95/MRANet)] 

* [arXiv:2408.03500] **e-Health CSIRO at RRG24: Entropy-Augmented Self-Critical Sequence Training for Radiology Report Generation**,
  Aaron Nicolson, Jinghui Liu, Jason Dowling, Anthony Nguyen, Bevan Koopman
  [[Paper](https://arxiv.org/abs/2408.03500)]
  [[Code](https://huggingface.co/aehrc/cxrmate-rrg24)] 
  
* [ACM MM 2024] **In-Context Learning for Zero-shot Medical Report Generation**,
  RUI Liu, Mingjie Li, Shen Zhao, Ling Chen, Xiaojun Chang, Lina Yao
  [[Paper](https://openreview.net/pdf?id=8zyG2eUgVE)] 

* [Nature 2023] Singhal, K., Azizi, S., Tu, T. et al. **Large language models encode clinical knowledge.** Nature 620, 172–180 (2023). https://doi.org/10.1038/s41586-023-06291-2
  [[Paper](https://www.nature.com/articles/s41586-023-06291-2)] 

* [Med-PaLM 2] **Towards Expert-Level Medical Question Answering with Large Language Models**,
  [[Paper](https://arxiv.org/pdf/2305.09617)]
  
* [Med-PaLM Multimodal (Med-PaLM M)] **Towards Generalist Biomedical AI**,
  Tao Tu∗, ‡, 1, Shekoofeh Azizi
  [[Paper](https://arxiv.org/pdf/2307.14334)]   
  
* [MedVersa] **A Generalist Learner for Multifaceted Medical Image Interpretation**, 
  Hong-Yu Zhou, Subathra Adithan, Julián Nicolás Acosta, Eric J. Topol, Pranav Rajpurkar
  [[Paper](https://arxiv.org/abs/2405.07988)] 
  
* [arXiv:2403.08002v2] **Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging**, 
Juan Manuel Zambrano Chaves, Shih-Cheng Huang, Yanbo Xu, Hanwen Xu, Naoto Usuyama, Sheng Zhang, Fei Wang, Yujia Xie, Mahmoud Khademi, Ziyi Yang, Hany Awadalla, Julia Gong, Houdong Hu, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Yu Gu, Cliff Wong, Mu Wei, Tristan Naumann, Muhao Chen, Matthew P. Lungren, Serena Yeung-Levy, Curtis P. Langlotz, Sheng Wang, Hoifung Poon
[[Paper](https://arxiv.org/abs/2403.08002v2)]   

* [arXiv:2403.08002] **Towards a clinically accessible radiology foundation model: open-access and lightweight, with automated evaluation**, 
  Juan Manuel Zambrano Chaves, Shih-Cheng Huang, Yanbo Xu, Hanwen Xu, Naoto Usuyama, Sheng Zhang, Fei Wang, Yujia Xie, Mahmoud Khademi, Ziyi Yang, Hany Awadalla, Julia Gong, Houdong Hu, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Yu Gu, Cliff Wong, Mu Wei, Tristan Naumann, Muhao Chen, Matthew P. Lungren, Akshay Chaudhari, Serena Yeung-Levy, Curtis P. Langlotz, Sheng Wang, Hoifung Poon
  [[Paper](https://arxiv.org/abs/2403.08002)]
  [[CheXprompt (Code)](https://github.com/microsoft/chexprompt)] 

* [CVPR2024] **MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant**,
  Chenlu Zhan, Yu Lin, Gaoang Wang, Hongwei Wang, Jian Wu
  [[Paper](https://arxiv.org/abs/2403.04290)] 

* **Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components**,
  Hermione Warr, Yasin Ibrahim, Daniel R. McGowan, Konstantinos Kamnitsas
  [[Paper](https://arxiv.org/abs/2407.21638)] 

* Zhao B N, JIANG X, Luo X, et al. **Large Multimodal Model for Real-World Radiology Report Generation**[J].
  [[Paper](https://openreview.net/pdf?id=3Jl0sjmZx9)]

* **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**, Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen
  [[Paper](https://arxiv.org/abs/2407.15362)]
  
* [arXiv:2407.15158] **HERGen: Elevating Radiology Report Generation with Longitudinal Data**, Fuying Wang, Shenghui Du, Lequan Yu, ECCV 2024, 
  [[Paper](https://arxiv.org/abs/2407.15158)]
  [[Code](https://github.com/fuying-wang/HERGen)] 
  
* **Eye Gaze Guided Cross-Modal Alignment Network for Radiology Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10596697)]  

* [ECCV 2024] **Contrastive Learning with Counterfactual Explanations for Radiology Report Generation**, 
  [[Paper](https://arxiv.org/pdf/2407.14474)]
  [[Code](https://github.com/mlii0117/CoFE)] 

* [IEEE TMI 2024] **Multi-Grained Radiology Report Generation With Sentence-Level Image-Language Contrastive Learning**, 
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10458706)] 

* [IEEE TMI 2024] **PhraseAug: An Augmented Medical Report Generation Model with Phrasebook**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10560051)] 

* [IEEE TMM 2023] **Semi-Supervised Medical Report Generation via Graph-Guided Hybrid Feature Consistency**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)] 

* [IEEE TMI 2024] **SGT++: Improved Scene Graph-Guided Transformer for Surgical Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10330637)] 

* [IEEE TNNLS] **Hybrid Reinforced Medical Report Generation With M-Linear Attention and Repetition Penalty**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10373187)]  

* [CIKM '23] Li, Qi. "**Harnessing the power of pre-trained vision-language models for efficient medical report generation**." Proceedings of the 32nd ACM International Conference on Information and Knowledge Management. 2023.

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMI 2024] **ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10522762)]
  [[Code](https://github.com/zhaozh10/ChatCAD)] 

* [IEEE TMI 2023] **Attributed Abnormality Graph Embedding for Clinically Accurate X-Ray Report Generation**,
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10045710)] 

* [IEEE TMM 2023] Multi-Task Paired Masking With Alignment Modeling for Medical Vision-Language Pre-Training
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10288259)]

* [IEEE TMI 2024] **Token-Mixer: Bind Image and Text in One Embedding Space for Medical Image Reporting**
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10552817)]
  [[Code](https://github.com/yangyan22/Token-Mixer)] 
  
* [arXiv:2405.04175] **Topic-wise Separable Sentence Retrieval for Medical Report Generation**,
  Junting Zhao, Yang Zhou, Zhihao Chen, Huazhu Fu, Liang Wan
  [[Paper](https://arxiv.org/abs/2405.04175)] 

* [WACV 2024] **CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs**,
  Junjie Shentu, Noura Al Moubayed,
  [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Shentu_CXR-IRGen_An_Integrated_Vision_and_Language_Model_for_the_Generation_WACV_2024_paper.pdf)]
  [[Code](https://github.com/junjie-shentu/CXR-IRGen)]

* [CVPR-2024] **Instance-level Expert Knowledge and Aggregate Discriminative Attention for Radiology Report Generation**, Shenshen Bu, Taiji Li, Yuedong Yang,*Zhiming Dai 
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Bu_Instance-level_Expert_Knowledge_and_Aggregate_Discriminative_Attention_for_Radiology_Report_CVPR_2024_paper.pdf)]
  [[Code](https://github.com/hnjzbss/EKAGen)] 

* [arXiv:2406.04449] **MAIRA-2: Grounded Radiology Report Generation**, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Anton Schwaighofer, Sam Bond-Taylor, Maximilian Ilse, Fernando Pérez-García, Valentina Salvatelli, Harshita Sharma, Felix Meissen, Mercy Ranjit, Shaury Srivastav, Julia Gong, Fabian Falck, Ozan Oktay, Anja Thieme, Matthew P. Lungren, Maria Teodora Wetscherek, Javier Alvarez-Valle, Stephanie L. Hyland
  [[Paper](https://arxiv.org/abs/2406.04449)] 

* [MICCAI 2024] **Textual Inversion and Self-supervised Refinement for Radiology Report Generation**, Yuanjiang Luo, Hongxiang Li, Xuan Wu, Meng Cao, Xiaoshuang Huang, Zhihong Zhu, Peixi Liao, Hu Chen, Yi Zhang
  [[Paper](https://arxiv.org/abs/2405.20607)]

* [arXiv:2405.19654] **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**,
  Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen
  [[Paper](https://arxiv.org/abs/2405.19654)]
  [[Code](https://github.com/SVT-Yang/MedST)] 

* [arXiv:2405.14113] **Multi-modality Regional Alignment Network for Covid X-Ray Survival Prediction and Report Generation**, 
  Zhusi Zhong, Jie Li, John Sollee, Scott Collins, Harrison Bai, Paul Zhang, Terrence Healey, Michael Atalay, Xinbo Gao, Zhicheng Jiao
  [[Paper](https://arxiv.org/abs/2405.14113)] 


* **FITA: Fine-grained Image-Text Aligner for Radiology Report Generation**,
  Honglong Yang, Hui Tang, Xiaomeng Li
  [[Paper](https://arxiv.org/abs/2405.00962)] 

* **A Disease Labeler for Chinese Chest X-Ray Report Generation**, arXiv:2404.16852, 
  Mengwei Wang, Ruixin Yan, Zeyi Hou, Ning Lang, Xiuzhuang Zhou
  [[Paper](https://arxiv.org/abs/2404.16852)] 

* "**Bootstrapping Large Language Models for Radiology Report Generation.**" Liu, Chang, et al.
Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 17. 2024.
[[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/29826)]
[[Code](https://github.com/synlp/R2-LLM)]

* [ICME 2024] **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**, arXiv:2404.11209, 
  Hongzhao Li, Hongyu Wang, Xia Sun, Hua He, Jun Feng
  [[Paper](https://arxiv.org/abs/2404.11209)] 

* [CVPR2024] **MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided Diffusion with Visual Invariant**, Chenlu Zhan, Yu Lin, Gaoang Wang, Hongwei Wang, Jian Wu
  [[Paper](https://arxiv.org/abs/2403.04290)] 

* [AAAI-2024] **PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation**, Haibo Jin1 , Haoxuan Che1, Yi Lin1, and Hao Chen
  [[Paper](https://arxiv.org/pdf/2308.12604.pdf)]
  [[Code](https://github.com/jhb86253817/PromptMRG)]

* [AAAI-2024] **MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models**, Yan Cai; Linlin Wang; Ye Wang; Gerard de Melo; Ya Zhang; Yan-Feng Wang; Liang He
  [[Paper](https://arxiv.org/abs/2312.12806)]
  
* [CVPR2024] **AHIVE: Anatomy-aware Hierarchical Vision Encoding for Interactive Radiology Report Retrieval**, Sixing Yan, William K. Cheung, Ivor W. Tsang, Keith Chiu, Terence M. Tong, Ka Chun Cheung, Simon See
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yan_AHIVE_Anatomy-aware_Hierarchical_Vision_Encoding_for_Interactive_Radiology_Report_Retrieval_CVPR_2024_paper.html)]
  
* [CVPR2024] **InVERGe: Intelligent Visual Encoder for Bridging Modalities in Report Generation (**Workshop**) **,  Ankan Deria, Komal Kumar, Snehashis Chakraborty, Dwarikanath Mahapatra, Sudipta Roy
  [[Paper](https://openaccess.thecvf.com/content/CVPR2024W/MULA/papers/Deria_InVERGe_Intelligent_Visual_Encoder_for_Bridging_Modalities_in_Report_Generation_CVPRW_2024_paper.pdf)]

  [[Code](https://github.com/labsroy007/InVERGe)]

* [ACL-2024] **DocLens: Multi-aspect Fine-grained Evaluation for Medical Text Generation**, Yiqing Xie, Sheng Zhang, Hao Cheng, Pengfei Liu, Zelalem Gero, Cliff Wong, Tristan Naumann, Hoifung Poon, Carolyn Rose
  [[paper](https://arxiv.org/abs/2311.09581)][[code](https://github.com/yiqingxyq/DocLens)]

  [[code](https://github.com/yiqingxyq/DocLens)]

* [ACL-2024] **SICAR at RRG2024: GPU Poor’s Guide to Radiology Report Generation**,  Kiartnarin Udomlapsakul, Parinthapat Pengpun, Tossaporn Saengja, Kanyakorn Veerakanjana, Krittamate Tiankanon, Pitikorn Khlaisamniang, Pasit Supholkhan, Amrest Chinkamol, Pubordee Aussavavirojekul, Hirunkul Phimsiri, Tara Sripo, Chiraphat Boonnag, Trongtum Tongdee,Thanongchai Siriapisith, Pairash Saiviroonporn, Jiramet Kinchagawat, Piyalitt Ittichaiwong

  [[paper](https://aclanthology.org/2024.bionlp-1.55.pdf)]

* [ACL-2024] **BiCAL: Bi-directional Contrastive Active Learning for Clinical Report Generation**,   Tianyi Wu, Jingqing Zhang, Wenjia Bai, Kai Sun

  [[paper](https://aclanthology.org/2024.bionlp-1.25.pdf)]

* [ACL-2024] **CID at RRG24: Attempting in a Conditionally Initiated Decoding of Radiology Report Generation with Clinical Entities**,  Yuxiang Liao*, Yuanbang Liang*, Yipeng Qin, Hantao Liu, Irena Spasi´ c

  [[paper](https://aclanthology.org/2024.bionlp-1.49.pdf)]

* [ACL-2024] **RadGraph-XL: A Large-Scale Expert-Annotated Dataset for Entity and Relation Extraction from Radiology Reports **, Jean-Benoit Delbrouck, Pierre Chambon, Zhihong Chen, Maya Varma, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Tan Bui, Steven Truong, Curtis Langlotz
  [[paper](https://aclanthology.org/2024.findings-acl.765.pdf#page=10&zoom=100,401,596)]

  [[code](https://github.com/Stanford-AIMI/radgraph)]

* [ACL-2024] **MLeVLM: Improve Multi-level Progressive Capabilities based on Multimodal Large Language Model for Medical Visual Question Answering **,Dexuan Xu, Yanyuan Chen, Jieyi Wang, Yue Huang, Hanpin Wang, Zhi Jin, Hongxing Wang, Weihua Yue, Jing He, Hang Li, Yu Huang
  [[paper](https://aclanthology.org/2024.findings-acl.296.pdf)]
  
  [[code](https://github.com/RyannChenOO/MLeVLM)]
  
* [ACL-2024] **Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable Cyclic Image-Report Generation **,Wenting Chen, Linlin Shen, Jingyang Lin, Jiebo Luo, Xiang Li, Yixuan Yuan
  [[paper](https://aclanthology.org/2024.acl-long.514.pdf)]
  
* [ICLR-2024] **LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation **,Suhyeon Lee, Won Jun Kim, Jinho Chang, Jong Chul Ye
  [[paper](https://arxiv.org/abs/2305.11490)]
  
  [[code](https://github.com/hyn2028/llm-cxr)]
  
* [ACM MM-2024] **Medical Report Generation via Multimodal Spatio-Temporal Fusion **,Xin Mei, Rui Mao, Xiaoyan Cai, Libin Yang, Erik Cambria
  [[paper](https://openreview.net/pdf?id=XKs7DR9GAK)]
  
* [ACM MM-2024] **Diffusion Networks with Task-Specific Noise Control for Radiology Report Generation **,Yuanhe Tian, Fei Xia, Yan Song
  [[paper](https://openreview.net/pdf?id=kbdeQmw2ny)]
  
* [ACM MM-2024] **Divide and Conquer: Isolating Normal-Abnormal Attributes in Knowledge Graph-Enhanced Radiology Report Generation **,Xiao Liang, Yanlei Zhang, Di Wang, Haodi Zhong, Ronghan Li, Quan Wang
  [[paper](https://openreview.net/forum?id=TuU8TQVOoj)]
  
* [ICLR-2024] **ICON: Improving Inter-Report Consistency of Radiology Report Generation via Lesion-aware Mix-up Augmentation**,Wenjun Hou, Yi Cheng, Kaishuai Xu, Yan Hu, Wenjie Li, Jiang Liu
  [[paper](https://arxiv.org/abs/2402.12844)]
  
  [[code](https://github.com/wjhou/ICon)]
  
* [ICLR-2024] **Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning**,Yuanpin Zhou, Huogen Wang
  [[paper](https://aclanthology.org/2024.emnlp-main.433.pdf)]
  
* [MICCAI-2024] **CT2Rep: Automated Radiology Report Generation for 3D Medical Imaging**,Ibrahim Ethem Hamamci, Sezgin Er, Bjoern Menze
  [[paper](https://arxiv.org/abs/2403.06801)]
  
  [[code](https://github.com/ibrahimethemhamamci/CT2Rep)]
  
* [MICCAI-2024] **WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole Slide Images**,Pingyi Chen, Honglin Li, Chenglu Zhu, Sunyi Zheng, Zhongyi Shui, Lin Yang
  [[paper](https://arxiv.org/abs/2311.16480)]
  
  [[code](https://github.com/cpystan/Wsi-Caption)]
  
* [MICCAI-2024] **Multivariate Cooperative Game for Image-Report Pairs: Hierarchical Semantic Alignment for Medical Report Generation**,Zhihong Zhu, Xuxin Cheng, Yunyan Zhang, Zhaorun Chen, Qingqing Long, Hongxiang Li, Zhiqi Huang, Xian Wu & Yefeng Zheng 
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-72384-1_29)]
  
* [MICCAI-2024] **MRScore: Evaluating Medical Report with LLM-Based Reward System**,Yunyi Liu, Zhanyu Wang, Yingshu Li, Xinyu Liang, Lingqiao Liu, Lei Wang, Luping Zhou
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-72384-1_27)]
  
* [MICCAI-2024] **Energy-Based Controllable Radiology Report Generation with Medical Knowledge **,Zeyi Hou, Ruixin Yan, Ziye Yan, Ning Lang & Xiuzhuang Zhou 
  [[paper](https://link.springer.com/chapter/10.1007/978-3-031-72086-4_23)]
  
* [MICCAI-2024] **GMoD: Graph-driven Momentum Distillation Framework with Active Perception of Disease Severity for Radiology Report Generation**,ZhiPeng Xiang, ShaoGuo Cui, CaoZhi Shang, Jingfeng Jiang & Liqiang Zhang 
  [[paper](https://papers.miccai.org/miccai-2024/paper/1733_paper.pdf)]
  
  [[code](https://github.com/xzp9999/GMoD-mian)]
  
* [MICCAI-2024] **TiBiX: Leveraging Temporal Information for Bidirectional X-ray and Report Generation (**MICCAI Workshop**)**,Santosh Sanjeev, Fadillah Adamsyah Maani, Arsen Abzhanov, Vijay Ram Papineni, Ibrahim Almakky, Bartłomiej W. Papież, Mohammad Yaqub
  [[paper](https://arxiv.org/pdf/2403.13343)]
  
  [[code](https://github.com/BioMedIA-MBZUAI/TiBiX)]
  
* [CIKM-2024] **CLR2G: Cross-modal Contrastive Learning on Radiology Report**,Mohammadreza Zolfaghari, Yi Zhu, Peter Gehler, Thomas Brox
  [[paper](https://dl.acm.org/doi/pdf/10.1145/3627673.3679668)]
  
* [WACV-2024] **Complex Organ Mask Guided Radiology Report Generation**,Tiancheng Gu, Dongnan Liu, Zhiyuan Li, Weidong Cai
  [[paper](https://arxiv.org/pdf/2311.02329)]
  
  [[code](https://github.com/GaryGuTC/COMG_model)]
  
* [ACCV-2024] **FG-CXR: A Radiologist-Aligned Gaze Dataset for Enhancing Interpretability in Chest X-Ray Report Generation**,Trong Thang Pham,Ngoc-VuongHo,Nhat-TanBui, Thinh Phan,
   Patel Brijesh,DonaldAdjeroh,GianfrancoDoretto,AnhNguyen,
   Carol C. W5,HienNguyen,andNganLe
  
  [[paper](https://vision.csee.wvu.edu/publications/phamHBPPADNWNL24accv.pdf)]
  
* [MedIA-2024] **From Vision to Text: A Comprehensive Review of Natural Image Captioning in Medical Diagnosis and Radiology Report Generation**,Gabriel Reale-Nosei, Elvira Amador-Domínguez
  , Emilio Serrano
  
  [[paper](https://www.sciencedirect.com/science/article/pii/S1361841524001890)]
  
* [MedIA-2024] **Enhancing the vision–language foundation model with key semantic knowledge-emphasized report refinement**,Weijian Huang, Cheng Li, Hao Yang, Jiarun Liu, Yong Liang, Hairong Zheng, Shanshan Wang

  [[paper](https://www.sciencedirect.com/science/article/pii/S136184152400224X)]
  
* [MedIA-2024] **DACG: Dual Attention and Context Guidance Model for Radiology Report Generation**,Wangyu Lang, Zhi Liu, Yijia Zhang

  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1361841524003025)]
  
  [[code](https://github.com/LangWY/DACG)]
  
* [TMI-2024] **An Organ-aware Diagnosis Framework for Radiology Report Generation**,Shiyu Li, Pengchong Qiao, Lin Wang, Munan Ning, Li Yuan, Yefeng Zheng, Jie Chen

  [[paper](https://ieeexplore.ieee.org/document/10579857)]
  
* [TMI-2024] **Attribute Prototype-guided Iterative Scene Graph for Explainable Radiology Report Generation**,Ke Zhang, Yan Yang, Jun Yu, Jianping Fan, Hanliang Jiang, Qingming Huang, Weidong Han

  [[paper](https://ieeexplore.ieee.org/document/10587279)]
  
* [TMI-2024] **A New Benchmark: Clinical Uncertainty and Severity Aware Labeled Chest X-Ray Images with Multi-Relationship Graph Learning**,Mengliang Zhang, Xinyue Hu, Lin Gu, Liangchen Liu, Kazuma Kobayashi, Tatsuya Harada, Yan Yan, Ronald M Summers, Yingying Zhu

  [[paper](https://ieeexplore.ieee.org/abstract/document/10632161)]
  
* [TMM-2024] **Multi-Level Objective Alignment Transformer for Fine-Grained Oral Panoramic X-Ray Report Generation**Nan Gao; Renyuan Yao, Ronghua Liang, Peng Chen; Tianshuang Liu,  Yuanjie Dang

  [[paper](https://ieeexplore.ieee.org/document/10443573)]
  
* [JBHI-2024] **CAMANet: Class Activation Map Guided Attention Network for Radiology Report Generation**,Jun Wang, Abhir Bhalerao, Terry Yin, Simon See, , and Yulan He

  [[paper](https://ieeexplore.ieee.org/document/10400776)]
  
  [[code](https://github.com/Markin-Wang/CAMANet)]
  
* [JBHI-2024] **TSGET: Two-Stage Global Enhanced Transformer for Automatic Radiology Report Generation**,Xiulong Yi,  You Fu, Ruiqing Liu, Hao Zhang, Rong Hua

  [[paper](https://ieeexplore.ieee.org/document/10381879)]
  
  [[code](https://github.com/Markin-Wang/CAMANet)]
  
* [Expert Systems with Applications-2024] **CheXReport: A transformer-based architecture to generate chest X-ray reports suggestions**,Felipe André Zeiser, Cristiano André da Costa, Gabriel de Oliveira Ramos, Andreas Maier, Rodrigo da Rosa Righi

  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417424015112)]
  
  [[code](https://github.com/felipezeiser/CheXReport)]
  
* [Knowledge-Based Systems-2024] **Automatic medical report generation combining contrastive learning and feature difference**,Chongwen Lyu, Chengjian Qiu, Kai Han, Saisai Li, Victor S. Sheng, Huan Rong , Yuqing Song, Yi Liu a, Zhe Liu

  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705124012644)]
  
* [Neurocomputing-2024] **Improving radiology report generation with multi-grained abnormality prediction**,Yuda Jin, Weidong Chen, Yuanhe Tian, Yan Song, Chenggang Yan

  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705124012644)]
  
* [Neurocomputing-2024] **An open chest X-ray dataset with benchmarks for automatic radiology report generation in French**,Hichem Metmer, Xiaoshan Yang

  [[paper](https://www.sciencedirect.com/science/article/pii/S0950705124012644)]
  
* [Neurocomputing-2024] **Trust it or not: Confidence-guided automatic radiology report generation**,Yixin Wang , Zihao Lin, Zhe Xu, Haoyu Dong, Jie Luo, Jiang Tian, Zhongchao Shi, Lifu Huang, Yang Zhang, Jianping Fan, Zhiqiang He

  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231224001450)]
  
* [Neurocomputing-2024] **VG-CALF: A vision-guided cross-attention and late-fusion network for radiology images in medical visual question answering**,Aiman Lameesa, Chaklam Silpasuwanchai, Md. Sakib Bin Alam

  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231224015017)]
  
* [Academic Radiology-2024] **Practical Evaluation of ChatGPT Performance for Radiology Report Generation**,Mohsen Soleimani, Navisa Seyyedi, Seyed Mohammad Ayyoubzadeh, Sharareh Rostam Niakan Kalhori, Hamidreza Keshavarz

  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231224015017)]
  
* [Radiology-2024] **Constructing a Large Language Model to Generate Impressions from Findings in Radiology Reports**,Lu Zhang*, Mingqian Liu*, Lingyun Wang, Yaping Zhang, Xiangjun Xu, Zhijun Pan, Yan Feng, Jue Zhao, Lin Zhang, Gehong Yao, Xu Chen, Xueqian Xie 

  [[paper](https://pubs.rsna.org/doi/pdf/10.1148/radiol.240885)]
  
* [Radiology-2024] **Comparing Commercial and Open-Source Large Language Models for Labeling Chest Radiograph Reports**,Felix J. Dorfner , Liv Jürgensen, Leonhard Donle, Fares Al Mohamad, Tobias R. Bodenmann, Mason C. Cleveland, Felix Busch, Lisa C. Adams, James Sato, Thomas Schultz, Albert E. Kim, Jameson Merkow, Keno K. Bressem, Christopher P. Bridge

  [[paper](https://pubs.rsna.org/doi/pdf/10.1148/radiol.240885)]
  
* [IEEE Transactions on Emerging Topics in Computational Intelligence-2024] **End-to-End Clustering Enhanced Contrastive Learning for Radiology Reports Generation**,Xinyao Liu, Junchang Xin, Qi Shen, Chuangang Li, Zhihong Huang, Zhiqiong Wang

  [[paper](https://pubs.rsna.org/doi/pdf/10.1148/radiol.240885)]
  
* [arXiv-2024] **Factual Serialization Enhancement: A Key Innovation for Chest X-ray Report Generation**,Kang Liu, Zhuoqi Ma, Mengmeng Liu, Zhicheng Jiao, Xiaolu Kang, Qiguang Miao, Kun Xie

  [[paper](https://pubs.rsna.org/doi/pdf/10.1148/radiol.240885)]
  
  [[code](https://github.com/mk-runner/FSE)]
  
* [arXiv-2024] **GREEN: Generative Radiology Report Evaluation and Error Notation**,Sophie Ostmeier, Justin Xu, Zhihong Chen, Maya Varma, Louis Blankemeier, Christian Bluethgen, Arne Edward Michalson, Michael Moseley, Curtis Langlotz, Akshay S Chaudhari, Jean-Benoit Delbrouck

  [[paper](https://arxiv.org/abs/2405.03595)]
  
* [arXiv-2024] **CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images and Patients**,Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang

  [[paper](https://arxiv.org/abs/2405.03595)]
  
  [[code](https://github.com/Stanford-AIMI/chexpert-plus)]
  
* [arXiv-2024] **Dia-LLaMA: Towards Large Language Model-driven CT Report Generation**,Zhixuan Chen, Luyang Luo, Yequan Bie, Hao Chen

  [[paper](https://arxiv.org/abs/2403.16386)]
  
* [arXiv-2024] **Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**,Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

  [[paper](https://arxiv.org/pdf/2406.07146)]
  
* [arXiv-2024] **The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It**,Aaron Nicolson, Shengyao Zhuang, Jason Dowling, Bevan Koopman

  [[paper](https://arxiv.org/pdf/2406.13181)]
  
  [[code](https://anonymous.4open.science/r/anon-D83E/README.md)]
  
* [arXiv-2024] **Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary**,Xingmeng Zhao, Tongnian Wang, Anthony Rios

  [[paper](https://arxiv.org/pdf/2406.13181)]
  
* [arXiv-2024] **X-ray Made Simple: Radiology Report Generation and Evaluation with Layman's Terms**,Kun Zhao, Chenghao Xiao, Chen Tang, Bohao Yang, Kai Ye, Noura Al Moubayed, Liang Zhan, Chenghua Lin

  [[paper](https://arxiv.org/abs/2406.17911)]
  
* [arXiv-2024] **Multi-modal vision-language model for generalizable annotation-free pathology localization and clinical diagnosis**,Hao Yang, Hong-Yu Zhou, Zhihuan Li, Yuanxu Gao, Cheng Li, Weijian Huang, Jiarun Liu, Hairong Zheng, Kang Zhang, Shanshan Wang

  [[paper](https://arxiv.org/pdf/2401.02044)]
  
  [[code](https://github.com/YH0517/AFLoc)]
  
* [arXiv-2024] **R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation**,Xiao Wang, Yuehang Li, Fuling Wang, Shiao Wang, Chuanfu Li, Bo Jiang

  [[paper](https://arxiv.org/pdf/2408.09743)]
  
  [[code](https://github.com/Event-AHU/Medical_Image_Analysis/tree/main/R2GenCSR)]
  
* [arXiv-2024] **Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation**,Oishi Banerjee, Hong-Yu Zhou, Subathra Adithan, Stephen Kwak, Kay Wu, Pranav Rajpurkar

  [[paper](https://arxiv.org/pdf/2406.06496)]
  
* [arXiv-2024] **M4CXR: Exploring Multi-task Potentials of Multi-modal Large Language Models for Chest X-ray Interpretation**,Jonggwon Park, Soobum Kim, Byungmu Yoon, Jihun Hyun, Kyoyun Choi

  [[paper](https://arxiv.org/pdf/2408.16213)]
  
* [arXiv-2024] **Democratizing MLLMs in Healthcare: TinyLLaVA-Med for Efficient Healthcare Diagnostics in Resource-Constrained Settings**,Aya El Mir, Lukelo Thadei Luoga, Boyuan Chen, Muhammad Abdullah Hanif, Muhammad Shafique

  [[paper](https://arxiv.org/pdf/2409.12184)]
  
* [arXiv-2024] **Expert-level vision-language foundation model for real-world radiology and comprehensive evaluation**,Xiaohong Liu, Guoxing Yang, Yulin Luo, Jiaji Mao, Xiang Zhang, Ming Gao, Shanghang Zhang, Jun Shen, Guangyu Wang

  [[paper](https://arxiv.org/pdf/2409.16183)]
  
* [arXiv-2024] **3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**,Hao Chen, Wei Zhao, Yingli Li, Tianyang Zhong, Yisong Wang, Youlan Shang, Lei Guo, Junwei Han, Tianming Liu, Jun Liu, Tuo Zhang

  [[paper](https://arxiv.org/pdf/2409.19330)]
  
* [arXiv-2024] **Image-aware Evaluation of Generated Medical Reports**,Gefen Dawidowicz, Elad Hirsch, Ayellet Tal

  [[paper](https://arxiv.org/pdf/2410.17357)]
  
* [arXiv-2024] **Text-Enhanced Medical Visual Question Answering**, Chih-Ying Liu , Fan Diao 

  [[paper](https://cs231n.stanford.edu/2024/papers/text-enhanced-medical-visual-question-answering.pdf)]
  
* [arXiv-2024] **MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models**,Peng Xia, Kangyu Zhu, Haoran Li, Tianze Wang, Weijia Shi, Sheng Wang, Linjun Zhang, James Zou, Huaxiu Yao

  [[paper](https://arxiv.org/pdf/2408.09743)]
  
  [[code](https://github.com/richard-peng-xia/MMed-RAG)]
  
* [arXiv-2024] **R2GEN-MAMBA:ASELECTIVESTATESPACEMODELFORRADIOLOGYREPORT GENERATION **, Yongheng Sun, Yueh Z. Lee, Genevieve A. Woodard, Hongtu Zhu, Chunfeng Lian,,Mingxia Liu

  [[paper](https://arxiv.org/pdf/2410.18135)]
  
  [[code](https://github.com/YonghengSun1997/R2Gen-Mamba)]
  
* [arXiv-2024] **Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs**, Xiaoman Zhang, Julián N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar

  [[paper](https://arxiv.org/abs/2408.14397)]
  
  [[code](https://github.com/rajpurkarlab/ReXKG)]
  
* [arXiv-2024] **Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model**, Peng Huang, Bowen Guo, Shuyu Liang, Junhu Fu, Yuanyuan Wang, Yi Guo

  [[paper](https://arxiv.org/pdf/2410.20165)]
  
* [arXiv-2024] **FINE-GRAINED VERIFIERS: PREFERENCE MODELING AS NEXT-TOKEN PREDICTION IN VISION-LANGUAGE ALIGNMENT**, Chenhang Cui, An Zhang, Yiyang Zhou, Zhaorun Chen, Gelei Deng, Huaxiu Yao, Tat-Seng Chua

  [[paper](https://arxiv.org/pdf/2410.14148)]
  
* 

  





### Year 2023 


* Li M, Lin B, Chen Z, et al. **Dynamic graph enhanced contrastive learning for chest x-ray report generation**[C]//
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3334-3343.
  [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Dynamic_Graph_Enhanced_Contrastive_Learning_for_Chest_X-Ray_Report_Generation_CVPR_2023_paper.pdf)]
  [[Code](https://github.com/mlii0117/DCL)] 
  
* Yang, Shuxin, et al. "**Radiology report generation with a learned knowledge base and multi-modal alignment.**" Medical Image Analysis 86 (2023): 102798.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841523000592)]
  [[Code](https://github.com/LX-doctorAI1/M2KT)]

* [MICCAI workshop 2023] Xiong, Yiheng, et al. "**Prior-RadGraphFormer: A Prior-Knowledge-Enhanced Transformer for Generating Radiology Graphs from X-Rays.**"
  International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature, Switzerland, 2023.
  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-55088-1_5)]
  [[Code](https://github.com/xiongyiheng/Prior-RadGraphFormer)] 

* [arXiv:2312.03970] **Improving Medical Report Generation with Adapter Tuning and Knowledge Enhancement in Vision-Language Foundation Models**, Shibin Wu, Bang Yang, Zhiyu Ye, Haoqian Wang, Hairong Zheng, Tong Zhang
  [[Paper](https://arxiv.org/abs/2312.03970)] 
  
* [arXiv:2303.09117] **Cross-Modal Causal Intervention for Medical Report Generation**, Weixing Chen, Yang Liu, Ce Wang, Jiarui Zhu, Shen Zhao, Guanbin Li, Cheng-Lin Liu, Liang Lin
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)] 

* [arXiv:2307.12526] **Rethinking Medical Report Generation: Disease Revealing Enhancement with Knowledge Graph**, Yixin Wang, Zihao Lin, Haoyu Dong
  [[Paper](https://arxiv.org/abs/2307.12526)] 

* [arXiv:2307.09758] **Longitudinal Data and a Semantic Similarity Reward for Chest X-Ray Report Generation**, Aaron Nicolson, Jason Dowling, Bevan Koopman
  [[Paper](https://arxiv.org/abs/2307.09758)]
  [[Code](https://github.com/aehrc/cxrmate)]

* "**Improving chest X-ray report generation by leveraging warm starting.**" Nicolson, Aaron, Jason Dowling, and Bevan Koopman.  Artificial intelligence in medicine 144 (2023): 102633.
[[Paper](https://www.sciencedirect.com/science/article/pii/S0933365723001471)]
[[Code](https://github.com/aehrc/cvt2distilgpt2)] 

* [arXiv:2310.05881, EMNLP 2023] **Controllable Chest X-Ray Report Generation from Longitudinal Representations**,
  Francesco Dalla Serra, Chaoyang Wang, Fani Deligianni, Jeffrey Dalton, Alison Q O'Neil
  [[Paper](https://arxiv.org/abs/2310.05881)] 

* **RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance**, Chantal Pellegrini, Ege Özsoy, Benjamin Busam, Nassir Navab, Matthias Keicher
  [[Paper](https://arxiv.org/abs/2311.18681)]
  [[Code](https://github.com/ChantalMP/RaDialog)] 

* **Visual-linguistic causal intervention for radiology report generation.** Chen, W., Liu, Y., Wang, C., Li, G., Zhu, J., & Lin, L. (2023). arXiv preprint arXiv:2303.09117.
  [[Paper](https://arxiv.org/abs/2303.09117)]
  [[Code](https://github.com/WissingChen/VLCI)]

* Zhang, Ke, et al. "**Semi-supervised Medical Report Generation via Graph-guided Hybrid Feature Consistency.**" IEEE Transactions on Multimedia (2023).
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10119200)]

* [ACL-2023] **ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning**, Wenjun Hou, Kaishuai Xu, Yi Cheng, Wenjie Li, Jiang Liu
  [[Paper](https://arxiv.org/pdf/2306.06466.pdf)]
  [[Code](https://github.com/wjhou/ORGan)]

* [EMNLP-2023] Hou, Wenjun, et al. "**RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning.**" Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.
  [[Paper](https://aclanthology.org/2023.findings-emnlp.140.pdf)]
  [[Code](https://github.com/wjhou/Recap)]





### Year 2022 


* **Uncertainty-aware report generation for chest X-rays by variational topic inference**,
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522002341?ref=pdf_download&fr=RR-2&rr=8c83a1612fa3dda2)] 

* **Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors**, Machine Learning for Health (ML4H) 2022
  [[Paper](https://proceedings.mlr.press/v193/ramesh22a/ramesh22a.pdf)] 

* Yang, Shuxin, et al. "**Knowledge matters: Chest radiology report generation with general and specific knowledge.**" Medical image analysis 80 (2022): 102510.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522001578)]
  [[Code](https://github.com/LX-doctorAI1/GSKET)] 

* [ECCV-2022] **Cross-modal prototype driven network for radiology report generation**. In European Conference on Computer Vision (pp. 563-579). Wang, J., Bhalerao, A., & He, Y. (2022, October). Cham: Springer Nature Switzerland.
  [[Paper](https://arxiv.org/pdf/2207.04818.pdf)]
  [[Code](https://github.com/Markin-Wang/XProNet)]

* Najdenkoska I, Zhen X, Worring M, et al. **Uncertainty-aware report generation for chest X-rays by variational topic inference**[J]. Medical Image Analysis, 2022, 82: 102603.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S1361841522002341)]


### Year 2021 and Before 


* Endo M, Krishnan R, Krishna V, et al. **Retrieval-based chest x-ray report generation using a pre-trained contrastive language-image model**[C]//Machine Learning for Health. PMLR, 2021: 209-219.
  [[Paper](https://proceedings.mlr.press/v158/endo21a/endo21a.pdf)] 
  [[Code](https://github.com/rajpurkarlab/CXR-RePaiR)] 

* "**Cross-modal Memory Networks for Radiology Report Generation.**" Chen, Zhihong, et al.  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.
  [[Paper](https://aclanthology.org/2021.acl-long.459/)]
  [[R2GenCMN-Code](https://github.com/zhjohnchan/R2GenCMN)]

* **On the Automatic Generation of Medical Imaging Reports**, Baoyu Jing, Pengtao Xie, Eric Xing
  [[Paper](https://arxiv.org/abs/1711.08195)]
  [[Code](https://github.com/ZexinYan/Medical-Report-Generation)] 

* [AAAI 2019] **CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison**,
  Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong, Safwan S. Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel, Matthew P. Lungren, Andrew Y. Ng 
  [[Paper](https://arxiv.org/abs/1901.07031)]
  [[Code](https://stanfordmlgroup.github.io/competitions/chexpert)]
  [[chexpert-labeler](https://github.com/stanfordmlgroup/chexpert-labeler)]





